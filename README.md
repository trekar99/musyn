<div align="center" style="display: flex; justify-content: center; align-items: center; text-align: center;">
  <a href="https://github.com/trekar99/musyn" style="margin-right: 20px; text-decoration: none; display: flex; align-items: center;">
    <img src="https://github.com/user-attachments/assets/b7a19a44-37f9-4245-9b43-499e3bdc7025" alt="Musyn" width="300">
  </a>
</div>
<div align="center" style="display: flex; justify-content: center; align-items: center; text-align: center;">
    <h2>
    Musyn: A Real-time Music-to-Image Co-creation System
    </h2>
</div>

## Overview
This repo contains an implementation of a real-time synesthetic musical co-creation system, that is, instantaneous generation of images based on the music being played. 

## Installation
```bash
./start.sh
```

## Usage

## Musyn Architecture

## Code Structure

## References
- [Exploring Real-Time Music-to-Image Systems for Creative Inspiration in Music Creation](https://arxiv.org/html/2407.05584v1#Sx3)
- [LP-MusicCaps: LLM-Based Pseudo Music Captioning](https://github.com/seungheondoh/lp-music-caps)
- [ArtSpew - An infinite number of monkeys randomly throwing paint at a canvas](https://github.com/aifartist/ArtSpew/)
- [SDXLTurbo](https://static1.squarespace.com/static/6213c340453c3f502425776e/t/65663480a92fba51d0e1023f/1701197769659/adversarial_diffusion_distillation.pdf)

## Next Steps
- [x] Generate Images in RT. 
- [ ] Option of 5s audio input.
- [ ] Improve RT Image Generation.
